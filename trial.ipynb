{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a1522d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e3cc6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a7ced4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai (from -r requirements.txt (line 1))\n",
      "  Using cached openai-2.6.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting ib_insync (from -r requirements.txt (line 2))\n",
      "  Using cached ib_insync-0.9.86-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pandas (from -r requirements.txt (line 3))\n",
      "  Using cached pandas-2.3.3-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting llama-index (from -r requirements.txt (line 4))\n",
      "  Using cached llama_index-0.14.6-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting jinja2 (from -r requirements.txt (line 5))\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting streamlit (from -r requirements.txt (line 6))\n",
      "  Using cached streamlit-1.50.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting python-dotenv (from -r requirements.txt (line 7))\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai->-r requirements.txt (line 1))\n",
      "  Using cached anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai->-r requirements.txt (line 1))\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai->-r requirements.txt (line 1))\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.10.0 (from openai->-r requirements.txt (line 1))\n",
      "  Using cached jiter-0.11.1-cp313-cp313-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai->-r requirements.txt (line 1))\n",
      "  Using cached pydantic-2.12.3-py3-none-any.whl.metadata (87 kB)\n",
      "Collecting sniffio (from openai->-r requirements.txt (line 1))\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai->-r requirements.txt (line 1))\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\shahab khan\\anaconda3\\envs\\myenv\\lib\\site-packages (from openai->-r requirements.txt (line 1)) (4.15.0)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 1))\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 1))\n",
      "  Using cached certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 1))\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 1))\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 1))\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.4 (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 1))\n",
      "  Using cached pydantic_core-2.41.4-cp313-cp313-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 1))\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting eventkit (from ib_insync->-r requirements.txt (line 2))\n",
      "  Using cached eventkit-1.0.3-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\shahab khan\\anaconda3\\envs\\myenv\\lib\\site-packages (from ib_insync->-r requirements.txt (line 2)) (1.6.0)\n",
      "Collecting numpy>=1.26.0 (from pandas->-r requirements.txt (line 3))\n",
      "  Using cached numpy-2.3.4-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\shahab khan\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->-r requirements.txt (line 3))\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->-r requirements.txt (line 3))\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting llama-index-cli<0.6,>=0.5.0 (from llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_index_cli-0.5.3-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting llama-index-core<0.15.0,>=0.14.6 (from llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_index_core-0.14.6-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting llama-index-embeddings-openai<0.6,>=0.5.0 (from llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_index_embeddings_openai-0.5.1-py3-none-any.whl.metadata (400 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_index_indices_managed_llama_cloud-0.9.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-index-llms-openai<0.7,>=0.6.0 (from llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_index_llms_openai-0.6.5-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting llama-index-readers-file<0.6,>=0.5.0 (from llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_index_readers_file-0.5.4-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_index_readers_llama_parse-0.5.1-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting nltk>3.8.1 (from llama-index->-r requirements.txt (line 4))\n",
      "  Using cached nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting aiohttp<4,>=3.8.6 (from llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached aiohttp-3.13.1-cp313-cp313-win_amd64.whl.metadata (8.4 kB)\n",
      "Collecting aiosqlite (from llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting banks<3,>=2.2.0 (from llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached banks-2.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting dataclasses-json (from llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting filetype<2,>=1.2.0 (from llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting fsspec>=2023.5.0 (from llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting llama-index-workflows<3,>=2 (from llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_index_workflows-2.8.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting networkx>=3.0 (from llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting pillow>=9.0.0 (from llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached pillow-12.0.0-cp313-cp313-win_amd64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\shahab khan\\anaconda3\\envs\\myenv\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4)) (4.5.0)\n",
      "Collecting pyyaml>=6.0.1 (from llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached pyyaml-6.0.3-cp313-cp313-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting requests>=2.31.0 (from llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in c:\\users\\shahab khan\\anaconda3\\envs\\myenv\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4)) (80.9.0)\n",
      "Collecting sqlalchemy>=1.4.49 (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached sqlalchemy-2.0.44-cp313-cp313-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.2.0 (from llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting tiktoken>=0.7.0 (from llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached tiktoken-0.12.0-cp313-cp313-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting wrapt (from llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached wrapt-2.0.0-cp313-cp313-win_amd64.whl.metadata (9.0 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached frozenlist-1.8.0-cp313-cp313-win_amd64.whl.metadata (21 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached multidict-6.7.0-cp313-cp313-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached propcache-0.4.1-cp313-cp313-win_amd64.whl.metadata (14 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached yarl-1.22.0-cp313-cp313-win_amd64.whl.metadata (77 kB)\n",
      "Collecting griffe (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached griffe-1.14.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting openai (from -r requirements.txt (line 1))\n",
      "  Using cached openai-1.109.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting beautifulsoup4<5,>=4.12.3 (from llama-index-readers-file<0.6,>=0.5.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached beautifulsoup4-4.14.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting defusedxml>=0.7.1 (from llama-index-readers-file<0.6,>=0.5.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting pandas (from -r requirements.txt (line 3))\n",
      "  Using cached pandas-2.2.3-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting pypdf<7,>=5.1.0 (from llama-index-readers-file<0.6,>=0.5.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached pypdf-6.1.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.6,>=0.5.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.6,>=0.5.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting llama-index-instrumentation>=0.1.0 (from llama-index-workflows<3,>=2->llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_index_instrumentation-0.4.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\shahab khan\\anaconda3\\envs\\myenv\\lib\\site-packages (from tqdm>4->openai->-r requirements.txt (line 1)) (0.4.6)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->-r requirements.txt (line 5))\n",
      "  Using cached markupsafe-3.0.3-cp313-cp313-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting altair!=5.4.0,!=5.4.1,<6,>=4.0 (from streamlit->-r requirements.txt (line 6))\n",
      "  Using cached altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.5.0 (from streamlit->-r requirements.txt (line 6))\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<7,>=4.0 (from streamlit->-r requirements.txt (line 6))\n",
      "  Using cached cachetools-6.2.1-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting click<9,>=7.0 (from streamlit->-r requirements.txt (line 6))\n",
      "  Using cached click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: packaging<26,>=20 in c:\\users\\shahab khan\\anaconda3\\envs\\myenv\\lib\\site-packages (from streamlit->-r requirements.txt (line 6)) (25.0)\n",
      "Collecting pillow>=9.0.0 (from llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached pillow-11.3.0-cp313-cp313-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting protobuf<7,>=3.20 (from streamlit->-r requirements.txt (line 6))\n",
      "  Using cached protobuf-6.33.0-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting pyarrow>=7.0 (from streamlit->-r requirements.txt (line 6))\n",
      "  Using cached pyarrow-22.0.0-cp313-cp313-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit->-r requirements.txt (line 6))\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit->-r requirements.txt (line 6))\n",
      "  Using cached watchdog-6.0.0-py3-none-win_amd64.whl.metadata (44 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit->-r requirements.txt (line 6))\n",
      "  Using cached gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit->-r requirements.txt (line 6))\n",
      "  Using cached pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in c:\\users\\shahab khan\\anaconda3\\envs\\myenv\\lib\\site-packages (from streamlit->-r requirements.txt (line 6)) (6.5.2)\n",
      "Collecting jsonschema>=3.0 (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit->-r requirements.txt (line 6))\n",
      "  Using cached jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting narwhals>=1.14.2 (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit->-r requirements.txt (line 6))\n",
      "  Using cached narwhals-2.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 6))\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 6))\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.31.0->llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl.metadata (38 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.31.0->llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting wrapt (from llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached wrapt-1.17.3-cp313-cp313-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit->-r requirements.txt (line 6))\n",
      "  Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit->-r requirements.txt (line 6))\n",
      "  Using cached referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit->-r requirements.txt (line 6))\n",
      "  Using cached rpds_py-0.28.0-cp313-cp313-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting llama-cloud==0.1.35 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_cloud-0.1.35-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_parse-0.6.76-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.76 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_cloud_services-0.6.76-py3-none-any.whl.metadata (3.3 kB)\n",
      "INFO: pip is looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_parse-0.6.75-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.75 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_cloud_services-0.6.75-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_parse-0.6.74-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.74 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_cloud_services-0.6.74-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_parse-0.6.73-py3-none-any.whl.metadata (6.6 kB)\n",
      "INFO: pip is still looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llama-cloud-services>=0.6.73 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_cloud_services-0.6.73-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_parse-0.6.72-py3-none-any.whl.metadata (6.6 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting llama-cloud-services>=0.6.72 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_cloud_services-0.6.72-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_parse-0.6.71-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.71 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_cloud_services-0.6.71-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_parse-0.6.70-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.70 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_cloud_services-0.6.70-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_parse-0.6.69-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.69 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_cloud_services-0.6.69-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_parse-0.6.68-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.68 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_cloud_services-0.6.68-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_parse-0.6.67-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.67 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_cloud_services-0.6.67-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_parse-0.6.66-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.66 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_cloud_services-0.6.66-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_parse-0.6.65-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.64 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_cloud_services-0.6.65-py3-none-any.whl.metadata (3.3 kB)\n",
      "  Using cached llama_cloud_services-0.6.64-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_parse-0.6.64-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Using cached llama_parse-0.6.63-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.63 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_cloud_services-0.6.63-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_parse-0.6.62-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.62 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_cloud_services-0.6.62-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_parse-0.6.60-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.60 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_cloud_services-0.6.60-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_parse-0.6.59-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.59 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_cloud_services-0.6.59-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_parse-0.6.58-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.58 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_cloud_services-0.6.58-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_parse-0.6.57-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.56 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_cloud_services-0.6.57-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached llama_cloud_services-0.6.56-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_parse-0.6.56-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Using cached llama_parse-0.6.55-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.55 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_cloud_services-0.6.55-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_parse-0.6.54-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.54 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached llama_cloud_services-0.6.54-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting joblib (from nltk>3.8.1->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk>3.8.1->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached regex-2025.10.23-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shahab khan\\anaconda3\\envs\\myenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 3)) (1.17.0)\n",
      "Collecting greenlet>=1 (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached greenlet-3.2.4-cp313-cp313-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.15.0,>=0.14.6->llama-index->-r requirements.txt (line 4))\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Using cached anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached jiter-0.11.1-cp313-cp313-win_amd64.whl (203 kB)\n",
      "Using cached pydantic-2.12.3-py3-none-any.whl (462 kB)\n",
      "Using cached pydantic_core-2.41.4-cp313-cp313-win_amd64.whl (2.0 MB)\n",
      "Using cached ib_insync-0.9.86-py3-none-any.whl (72 kB)\n",
      "Using cached llama_index-0.14.6-py3-none-any.whl (7.4 kB)\n",
      "Using cached llama_index_cli-0.5.3-py3-none-any.whl (28 kB)\n",
      "Using cached llama_index_core-0.14.6-py3-none-any.whl (11.9 MB)\n",
      "Using cached aiohttp-3.13.1-cp313-cp313-win_amd64.whl (450 kB)\n",
      "Using cached banks-2.2.0-py3-none-any.whl (29 kB)\n",
      "Using cached dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Using cached llama_index_embeddings_openai-0.5.1-py3-none-any.whl (7.0 kB)\n",
      "Using cached llama_index_llms_openai-0.6.5-py3-none-any.whl (26 kB)\n",
      "Using cached openai-1.109.1-py3-none-any.whl (948 kB)\n",
      "Using cached llama_index_readers_file-0.5.4-py3-none-any.whl (51 kB)\n",
      "Using cached pandas-2.2.3-cp313-cp313-win_amd64.whl (11.5 MB)\n",
      "Using cached beautifulsoup4-4.14.2-py3-none-any.whl (106 kB)\n",
      "Using cached llama_index_workflows-2.8.3-py3-none-any.whl (61 kB)\n",
      "Using cached multidict-6.7.0-cp313-cp313-win_amd64.whl (45 kB)\n",
      "Using cached pypdf-6.1.3-py3-none-any.whl (323 kB)\n",
      "Using cached striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached yarl-1.22.0-cp313-cp313-win_amd64.whl (86 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached streamlit-1.50.0-py3-none-any.whl (10.1 MB)\n",
      "Using cached altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Using cached cachetools-6.2.1-py3-none-any.whl (11 kB)\n",
      "Using cached click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Using cached gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached numpy-2.3.4-cp313-cp313-win_amd64.whl (12.8 MB)\n",
      "Using cached pillow-11.3.0-cp313-cp313-win_amd64.whl (7.0 MB)\n",
      "Using cached protobuf-6.33.0-cp310-abi3-win_amd64.whl (436 kB)\n",
      "Using cached pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl (107 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached watchdog-6.0.0-py3-none-win_amd64.whl (79 kB)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Using cached certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Using cached Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Using cached wrapt-1.17.3-cp313-cp313-win_amd64.whl (38 kB)\n",
      "Using cached frozenlist-1.8.0-cp313-cp313-win_amd64.whl (43 kB)\n",
      "Using cached fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "Using cached llama_index_indices_managed_llama_cloud-0.9.4-py3-none-any.whl (17 kB)\n",
      "Using cached llama_cloud-0.1.35-py3-none-any.whl (303 kB)\n",
      "Using cached llama_index_instrumentation-0.4.2-py3-none-any.whl (15 kB)\n",
      "Using cached llama_index_readers_llama_parse-0.5.1-py3-none-any.whl (3.2 kB)\n",
      "Using cached llama_parse-0.6.54-py3-none-any.whl (4.9 kB)\n",
      "Using cached llama_cloud_services-0.6.54-py3-none-any.whl (63 kB)\n",
      "Using cached markupsafe-3.0.3-cp313-cp313-win_amd64.whl (15 kB)\n",
      "Using cached narwhals-2.9.0-py3-none-any.whl (422 kB)\n",
      "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "Using cached nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "Using cached propcache-0.4.1-cp313-cp313-win_amd64.whl (40 kB)\n",
      "Using cached pyarrow-22.0.0-cp313-cp313-win_amd64.whl (28.0 MB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached pyyaml-6.0.3-cp313-cp313-win_amd64.whl (154 kB)\n",
      "Using cached referencing-0.37.0-py3-none-any.whl (26 kB)\n",
      "Using cached regex-2025.10.23-cp313-cp313-win_amd64.whl (276 kB)\n",
      "Using cached rpds_py-0.28.0-cp313-cp313-win_amd64.whl (227 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached soupsieve-2.8-py3-none-any.whl (36 kB)\n",
      "Using cached sqlalchemy-2.0.44-cp313-cp313-win_amd64.whl (2.1 MB)\n",
      "Using cached greenlet-3.2.4-cp313-cp313-win_amd64.whl (299 kB)\n",
      "Using cached tiktoken-0.12.0-cp313-cp313-win_amd64.whl (879 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached aiosqlite-0.21.0-py3-none-any.whl (15 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached eventkit-1.0.3-py3-none-any.whl (31 kB)\n",
      "Using cached griffe-1.14.0-py3-none-any.whl (144 kB)\n",
      "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Installing collected packages: striprtf, pytz, filetype, dirtyjson, wrapt, watchdog, urllib3, tzdata, typing-inspection, tqdm, toml, tenacity, soupsieve, sniffio, smmap, rpds-py, regex, pyyaml, python-dotenv, pypdf, pydantic-core, pyarrow, protobuf, propcache, pillow, numpy, networkx, narwhals, mypy-extensions, multidict, marshmallow, MarkupSafe, joblib, jiter, idna, h11, griffe, greenlet, fsspec, frozenlist, distro, defusedxml, click, charset_normalizer, certifi, cachetools, blinker, attrs, annotated-types, aiosqlite, aiohappyeyeballs, yarl, typing-inspect, sqlalchemy, requests, referencing, pydantic, pandas, nltk, jinja2, httpcore, gitdb, eventkit, deprecated, beautifulsoup4, anyio, aiosignal, tiktoken, pydeck, llama-index-instrumentation, jsonschema-specifications, ib_insync, httpx, gitpython, dataclasses-json, banks, aiohttp, openai, llama-index-workflows, llama-cloud, jsonschema, llama-index-core, altair, streamlit, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-cli, llama-index-readers-llama-parse, llama-index\n",
      "\n",
      "   ----------------------------------------  1/93 [pytz]\n",
      "    ---------------------------------------  2/93 [filetype]\n",
      "   -- -------------------------------------  6/93 [urllib3]\n",
      "   --- ------------------------------------  7/93 [tzdata]\n",
      "   --- ------------------------------------  7/93 [tzdata]\n",
      "   ---- ----------------------------------- 10/93 [toml]\n",
      "   ------ --------------------------------- 15/93 [rpds-py]\n",
      "   ------- -------------------------------- 17/93 [pyyaml]\n",
      "   -------- ------------------------------- 19/93 [pypdf]\n",
      "   -------- ------------------------------- 20/93 [pydantic-core]\n",
      "   --------- ------------------------------ 21/93 [pyarrow]\n",
      "   --------- ------------------------------ 21/93 [pyarrow]\n",
      "   --------- ------------------------------ 21/93 [pyarrow]\n",
      "   --------- ------------------------------ 21/93 [pyarrow]\n",
      "   --------- ------------------------------ 21/93 [pyarrow]\n",
      "   --------- ------------------------------ 21/93 [pyarrow]\n",
      "   --------- ------------------------------ 21/93 [pyarrow]\n",
      "   --------- ------------------------------ 22/93 [protobuf]\n",
      "   --------- ------------------------------ 22/93 [protobuf]\n",
      "   ---------- ----------------------------- 24/93 [pillow]\n",
      "   ---------- ----------------------------- 24/93 [pillow]\n",
      "   ---------- ----------------------------- 25/93 [numpy]\n",
      "   ---------- ----------------------------- 25/93 [numpy]\n",
      "   ---------- ----------------------------- 25/93 [numpy]\n",
      "   ---------- ----------------------------- 25/93 [numpy]\n",
      "   ---------- ----------------------------- 25/93 [numpy]\n",
      "   ---------- ----------------------------- 25/93 [numpy]\n",
      "   ---------- ----------------------------- 25/93 [numpy]\n",
      "   ---------- ----------------------------- 25/93 [numpy]\n",
      "   ---------- ----------------------------- 25/93 [numpy]\n",
      "   ---------- ----------------------------- 25/93 [numpy]\n",
      "   ---------- ----------------------------- 25/93 [numpy]\n",
      "   ---------- ----------------------------- 25/93 [numpy]\n",
      "   ---------- ----------------------------- 25/93 [numpy]\n",
      "   ---------- ----------------------------- 25/93 [numpy]\n",
      "   ----------- ---------------------------- 26/93 [networkx]\n",
      "   ----------- ---------------------------- 26/93 [networkx]\n",
      "   ----------- ---------------------------- 26/93 [networkx]\n",
      "   ----------- ---------------------------- 26/93 [networkx]\n",
      "   ----------- ---------------------------- 26/93 [networkx]\n",
      "   ----------- ---------------------------- 26/93 [networkx]\n",
      "   ----------- ---------------------------- 26/93 [networkx]\n",
      "   ----------- ---------------------------- 26/93 [networkx]\n",
      "   ----------- ---------------------------- 26/93 [networkx]\n",
      "   ----------- ---------------------------- 26/93 [networkx]\n",
      "   ----------- ---------------------------- 26/93 [networkx]\n",
      "   ----------- ---------------------------- 26/93 [networkx]\n",
      "   ----------- ---------------------------- 27/93 [narwhals]\n",
      "   ----------- ---------------------------- 27/93 [narwhals]\n",
      "   ----------- ---------------------------- 27/93 [narwhals]\n",
      "   ------------ --------------------------- 29/93 [multidict]\n",
      "   ------------- -------------------------- 32/93 [joblib]\n",
      "   ------------- -------------------------- 32/93 [joblib]\n",
      "   --------------- ------------------------ 36/93 [griffe]\n",
      "   --------------- ------------------------ 36/93 [griffe]\n",
      "   ---------------- ----------------------- 38/93 [fsspec]\n",
      "   ---------------- ----------------------- 38/93 [fsspec]\n",
      "   ------------------ --------------------- 43/93 [charset_normalizer]\n",
      "   -------------------- ------------------- 47/93 [attrs]\n",
      "   ---------------------- ----------------- 53/93 [sqlalchemy]\n",
      "   ---------------------- ----------------- 53/93 [sqlalchemy]\n",
      "   ---------------------- ----------------- 53/93 [sqlalchemy]\n",
      "   ---------------------- ----------------- 53/93 [sqlalchemy]\n",
      "   ---------------------- ----------------- 53/93 [sqlalchemy]\n",
      "   ---------------------- ----------------- 53/93 [sqlalchemy]\n",
      "   ---------------------- ----------------- 53/93 [sqlalchemy]\n",
      "   ---------------------- ----------------- 53/93 [sqlalchemy]\n",
      "   ---------------------- ----------------- 53/93 [sqlalchemy]\n",
      "   ----------------------- ---------------- 55/93 [referencing]\n",
      "   ------------------------ --------------- 56/93 [pydantic]\n",
      "   ------------------------ --------------- 56/93 [pydantic]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 57/93 [pandas]\n",
      "   ------------------------ --------------- 58/93 [nltk]\n",
      "   ------------------------ --------------- 58/93 [nltk]\n",
      "   ------------------------ --------------- 58/93 [nltk]\n",
      "   ------------------------ --------------- 58/93 [nltk]\n",
      "   ------------------------ --------------- 58/93 [nltk]\n",
      "   ------------------------ --------------- 58/93 [nltk]\n",
      "   ------------------------ --------------- 58/93 [nltk]\n",
      "   ------------------------ --------------- 58/93 [nltk]\n",
      "   ------------------------ --------------- 58/93 [nltk]\n",
      "   ------------------------- -------------- 59/93 [jinja2]\n",
      "   ------------------------- -------------- 60/93 [httpcore]\n",
      "   -------------------------- ------------- 62/93 [eventkit]\n",
      "   --------------------------- ------------ 65/93 [anyio]\n",
      "   ---------------------------- ----------- 67/93 [tiktoken]\n",
      "   ----------------------------- ---------- 68/93 [pydeck]\n",
      "   ------------------------------ --------- 71/93 [ib_insync]\n",
      "   ------------------------------ --------- 72/93 [httpx]\n",
      "   ------------------------------- -------- 73/93 [gitpython]\n",
      "   -------------------------------- ------- 76/93 [aiohttp]\n",
      "   -------------------------------- ------- 76/93 [aiohttp]\n",
      "   --------------------------------- ------ 77/93 [openai]\n",
      "   --------------------------------- ------ 77/93 [openai]\n",
      "   --------------------------------- ------ 77/93 [openai]\n",
      "   --------------------------------- ------ 77/93 [openai]\n",
      "   --------------------------------- ------ 77/93 [openai]\n",
      "   --------------------------------- ------ 77/93 [openai]\n",
      "   --------------------------------- ------ 77/93 [openai]\n",
      "   --------------------------------- ------ 77/93 [openai]\n",
      "   --------------------------------- ------ 77/93 [openai]\n",
      "   --------------------------------- ------ 77/93 [openai]\n",
      "   --------------------------------- ------ 77/93 [openai]\n",
      "   --------------------------------- ------ 77/93 [openai]\n",
      "   --------------------------------- ------ 77/93 [openai]\n",
      "   --------------------------------- ------ 79/93 [llama-cloud]\n",
      "   --------------------------------- ------ 79/93 [llama-cloud]\n",
      "   --------------------------------- ------ 79/93 [llama-cloud]\n",
      "   --------------------------------- ------ 79/93 [llama-cloud]\n",
      "   --------------------------------- ------ 79/93 [llama-cloud]\n",
      "   --------------------------------- ------ 79/93 [llama-cloud]\n",
      "   ---------------------------------- ----- 80/93 [jsonschema]\n",
      "   ---------------------------------- ----- 81/93 [llama-index-core]\n",
      "   ---------------------------------- ----- 81/93 [llama-index-core]\n",
      "   ---------------------------------- ----- 81/93 [llama-index-core]\n",
      "   ---------------------------------- ----- 81/93 [llama-index-core]\n",
      "   ---------------------------------- ----- 81/93 [llama-index-core]\n",
      "   ---------------------------------- ----- 81/93 [llama-index-core]\n",
      "   ---------------------------------- ----- 81/93 [llama-index-core]\n",
      "   ---------------------------------- ----- 81/93 [llama-index-core]\n",
      "   ---------------------------------- ----- 81/93 [llama-index-core]\n",
      "   ----------------------------------- ---- 82/93 [altair]\n",
      "   ----------------------------------- ---- 82/93 [altair]\n",
      "   ----------------------------------- ---- 82/93 [altair]\n",
      "   ----------------------------------- ---- 83/93 [streamlit]\n",
      "   ----------------------------------- ---- 83/93 [streamlit]\n",
      "   ----------------------------------- ---- 83/93 [streamlit]\n",
      "   ----------------------------------- ---- 83/93 [streamlit]\n",
      "   ----------------------------------- ---- 83/93 [streamlit]\n",
      "   ----------------------------------- ---- 83/93 [streamlit]\n",
      "   ----------------------------------- ---- 83/93 [streamlit]\n",
      "   ----------------------------------- ---- 83/93 [streamlit]\n",
      "   ----------------------------------- ---- 83/93 [streamlit]\n",
      "   ------------------------------------ --- 84/93 [llama-index-readers-file]\n",
      "   ------------------------------------- -- 88/93 [llama-cloud-services]\n",
      "   -------------------------------------- - 90/93 [llama-index-cli]\n",
      "   ---------------------------------------- 93/93 [llama-index]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.3 aiohappyeyeballs-2.6.1 aiohttp-3.13.1 aiosignal-1.4.0 aiosqlite-0.21.0 altair-5.5.0 annotated-types-0.7.0 anyio-4.11.0 attrs-25.4.0 banks-2.2.0 beautifulsoup4-4.14.2 blinker-1.9.0 cachetools-6.2.1 certifi-2025.10.5 charset_normalizer-3.4.4 click-8.3.0 dataclasses-json-0.6.7 defusedxml-0.7.1 deprecated-1.2.18 dirtyjson-1.0.8 distro-1.9.0 eventkit-1.0.3 filetype-1.2.0 frozenlist-1.8.0 fsspec-2025.9.0 gitdb-4.0.12 gitpython-3.1.45 greenlet-3.2.4 griffe-1.14.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 ib_insync-0.9.86 idna-3.11 jinja2-3.1.6 jiter-0.11.1 joblib-1.5.2 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 llama-cloud-0.1.35 llama-cloud-services-0.6.54 llama-index-0.14.6 llama-index-cli-0.5.3 llama-index-core-0.14.6 llama-index-embeddings-openai-0.5.1 llama-index-indices-managed-llama-cloud-0.9.4 llama-index-instrumentation-0.4.2 llama-index-llms-openai-0.6.5 llama-index-readers-file-0.5.4 llama-index-readers-llama-parse-0.5.1 llama-index-workflows-2.8.3 llama-parse-0.6.54 marshmallow-3.26.1 multidict-6.7.0 mypy-extensions-1.1.0 narwhals-2.9.0 networkx-3.5 nltk-3.9.2 numpy-2.3.4 openai-1.109.1 pandas-2.2.3 pillow-11.3.0 propcache-0.4.1 protobuf-6.33.0 pyarrow-22.0.0 pydantic-2.12.3 pydantic-core-2.41.4 pydeck-0.9.1 pypdf-6.1.3 python-dotenv-1.2.1 pytz-2025.2 pyyaml-6.0.3 referencing-0.37.0 regex-2025.10.23 requests-2.32.5 rpds-py-0.28.0 smmap-5.0.2 sniffio-1.3.1 soupsieve-2.8 sqlalchemy-2.0.44 streamlit-1.50.0 striprtf-0.0.26 tenacity-9.1.2 tiktoken-0.12.0 toml-0.10.2 tqdm-4.67.1 typing-inspect-0.9.0 typing-inspection-0.4.2 tzdata-2025.2 urllib3-2.5.0 watchdog-6.0.0 wrapt-1.17.3 yarl-1.22.0\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021291e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
